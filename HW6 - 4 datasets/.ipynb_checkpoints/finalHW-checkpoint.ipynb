{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706ff59b",
   "metadata": {},
   "source": [
    "# INFO 371 - Final Homework \n",
    "\n",
    "For this homework assignment, we are going to ask to you to put together everything you have learned throughout the quarter to analyze 4 very different datasets! The goal is for you to gain experience and intuition for how each of the supervised learning algorithms perform in different scenarios. \n",
    "\n",
    "# Datasets \n",
    "There are four datasets you will need to analyze (one of which you have worked with in past asignments!) \n",
    "\n",
    "## Dataset 1: Soybean Dataset\n",
    "With this dataset (``soybean.csv``) your goal is to predict which of the four diseases a particular soy-bean plant has. This datset was part of a project used to build a survey to diagnose crops (you can read more about this work [here](http://www.mli.gmu.edu/papers/79-80/80-2.pdf). The dataset has the following features: \n",
    "\n",
    "* Month: which month was the plant disease found, represented as a number meaning april is 4 ect.\n",
    "* Plant Stand: describes how much of the soybean plant is above the soil \n",
    "    * 0 is avg,  1 is below avg\n",
    "* Precipitation:  0: below avg, 1: avg, 2: above avg\n",
    "* temp:  0: below avg, 1: avg, 2: above avg\n",
    "* hail: 0 is no, 1 is yes \n",
    "* crop-hist\t\n",
    "    * 0: diff-lst-year\n",
    "    * 1: same-lst-yr\n",
    "    * 2: same-lst-two-yrs\n",
    "    * 3: same-lst-sev-yrs\n",
    "* area-damaged\n",
    "    * 0: scattered\n",
    "    * 1: low-areas\n",
    "    * 2: upper-areas\n",
    "    * 3:whole-field\n",
    "* severity\n",
    "    * 0 minor,1: potentially severe, 2: severe\n",
    "* seed-tmt: 0: None, 1: used fungicide \n",
    "* germination: How much of the plants sprouted\n",
    "    * 0: 90-100%, 1: 80-89%, 2: 80% or less\t\n",
    "* plant-growth: 0: normal, 1: abnormal \n",
    "* leaves: 0: normal, 1: abnormal \n",
    "* leafspots-halo: 0: absent: 1: has yellow halos, 2: has halos, but not yellow halos\n",
    "* leafspots-margin: 0: water-soaked margin,1: no margin, 2: does not apply \t\n",
    "* leafspot-size: 0: less than 1/8 in, 1: bigger than 1/8 in, 2: does not apply\n",
    "* leaf-shread: \t0: absent, 1: present\n",
    "* leaf-malf: 0: absent, 1: present\n",
    "* leaf-mild: 0: absent, 1: present on upper surface ,2: present on lower surface\n",
    "* stem: 0: normal, 1: not normal \n",
    "* lodging: 0: absent, 1: present\n",
    "* stem-cankers: 0: absent, 1: found below soil, 2: found above soil, 3: found above second node\n",
    "* canker-lesion\t0: absent,1: brown color ,2: dark brown to black color, 3: tan\n",
    "* fruiting-bodies: \t0: absent, 1: present\n",
    "* extern_decay: 0: absent, 1: firm and dry, 2: watery \n",
    "* mycelium: 0: absent, 1: present\t\n",
    "* int-discolor: 0: none, 1: black, 2: brown \n",
    "* sclerotia: 0: absent, 1: present\t\n",
    "* fruit-pods: 0: normal, 1: diseased, 2: few present, 3: does not apply \t\n",
    "* fruit-spots: 0: absent, 1: colored, 2: brown with black specks, 3: distorted, 4: does not apply\t\n",
    "* seed: 0: normal, 1: not normal\n",
    "* mold-groth: 0: absent, 1: present\n",
    "* seed-discolor: 0: absent, 1: present\n",
    "* seed-size: 0: average, 1: below average \t\n",
    "* shriveling: 0: absent, 1: present\t\n",
    "* roots\t: 0: normal, 1: diseased \n",
    "\n",
    "\n",
    "* Label: which of the diseases that plat has\n",
    "    * D1: diaporthe stem canker\n",
    "    * D2: charcoal rot\n",
    "    * D3: rhizoctonia root rot\n",
    "    * D4: phytophthora rot\n",
    "\n",
    "\n",
    "## Dataset 2: Iris Dataset\n",
    "With this dataset (``iris.csv``), your goal to categorize Iris flowers based on the four measurements (aka: features) into the correct species (aka: labels) setosa, virginica, and versicolor. The data contains 50 flowers of each species (150 in total), and four measurements for each species (petal length and width, and sepal length and width). All of these are numeric measures.\n",
    "\n",
    "## Dataset 3: Skin Segmentation Dataset\n",
    "With this dataset (``Skin_NonSkin.tsv``), your goal is to predict whether a particular pixel is a skin tone or not a skin tone. Each row in the dataset is a pixel taken from a random image. The features are the values in the B, G, R color space (i.e blue, green, red). \n",
    "\n",
    "## Dataset 4: Taiwanese Bankruptcy Prediction Dataset \n",
    "With this dataset (``bankruptcy.csv``), your goal is to predict whether a company went backrupt or not. This dataset was collected from the Taiwan Economic Journal for the years 1999 to 2009. Company bankruptcy was defined based on the business regulations of the Taiwan Stock Exchange. The dataset has the following features: \n",
    "\n",
    "* Bankrupt?: Class label\n",
    "* ROA(C) before interest and depreciation before interest: Return On Total Assets(C)\n",
    "* ROA(A) before interest and % after tax: Return On Total Assets(A)\n",
    "* ROA(B) before interest and depreciation after tax: Return On Total Assets(B)\n",
    "* Operating Gross Margin: Gross Profit/Net Sales\n",
    "* Realized Sales Gross Margin: Realized Gross Profit/Net Sales\n",
    "* Operating Profit Rate: Operating Income/Net Sales\n",
    "* Pre-tax net Interest Rate: Pre-Tax Income/Net Sales\n",
    "* After-tax net Interest Rate: Net Income/Net Sales\n",
    "* Non-industry income and expenditure/revenue: Net Non-operating Income Ratio\n",
    "* Continuous interest rate (after tax): Net Income-Exclude Disposal Gain or Loss/Net Sales\n",
    "* Operating Expense Rate: Operating Expenses/Net Sales\n",
    "* Research and development expense rate: (Research and Development Expenses)/Net Sales\n",
    "* Cash flow rate: Cash Flow from Operating/Current Liabilities\n",
    "* Interest-bearing debt interest rate: Interest-bearing Debt/Equity\n",
    "* Tax rate (A): Effective Tax Rate\n",
    "* Net Value Per Share (B): Book Value Per Share(B)\n",
    "* Net Value Per Share (A): Book Value Per Share(A)\n",
    "* Net Value Per Share (C): Book Value Per Share(C)\n",
    "* Persistent EPS in the Last Four Seasons: EPS-Net Income\n",
    "* Cash Flow Per Share\n",
    "* Revenue Per Share (Yuan ¥): Sales Per Share\n",
    "* Operating Profit Per Share (Yuan ¥): Operating Income Per Share\n",
    "* Per Share Net profit before tax (Yuan ¥): Pretax Income Per Share\n",
    "* Realized Sales Gross Profit Growth Rate\n",
    "* Operating Profit Growth Rate: Operating Income Growth\n",
    "* After-tax Net Profit Growth Rate: Net Income Growth\n",
    "* Regular Net Profit Growth Rate: Continuing Operating Income after Tax Growth\n",
    "* Continuous Net Profit Growth Rate: Net Income-Excluding Disposal Gain or Loss Growth\n",
    "* Total Asset Growth Rate: Total Asset Growth\n",
    "* Net Value Growth Rate: Total Equity Growth\n",
    "* Total Asset Return Growth Rate Ratio: Return on Total Asset Growth\n",
    "* Cash Reinvestment %: Cash Reinvestment Ratio\n",
    "* Current Ratio\n",
    "* Quick Ratio: Acid Test\n",
    "* Interest Expense Ratio: Interest Expenses/Total Revenue\n",
    "* Total debt/Total net worth: Total Liability/Equity Ratio\n",
    "* Debt ratio %: Liability/Total Assets\n",
    "* Net worth/Assets: Equity/Total Assets\n",
    "* Long-term fund suitability ratio (A): (Long-term Liability+Equity)/Fixed Assets\n",
    "* Borrowing dependency: Cost of Interest-bearing Debt\n",
    "* Contingent liabilities/Net worth: Contingent Liability/Equity\n",
    "* Operating profit/Paid-in capital: Operating Income/Capital\n",
    "* Net profit before tax/Paid-in capital: Pretax Income/Capital\n",
    "* Inventory and accounts receivable/Net value: (Inventory+Accounts Receivables)/Equity\n",
    "* Total Asset Turnover\n",
    "* Accounts Receivable Turnover\n",
    "* Average Collection Days: Days Receivable Outstanding\n",
    "* Inventory Turnover Rate (times)\n",
    "* Fixed Assets Turnover Frequency\n",
    "* Net Worth Turnover Rate (times): Equity Turnover\n",
    "* Revenue per person: Sales Per Employee\n",
    "* Operating profit per person: Operation Income Per Employee\n",
    "* Allocation rate per person: Fixed Assets Per Employee\n",
    "* Working Capital to Total Assets\n",
    "* Quick Assets/Total Assets\n",
    "* Current Assets/Total Assets\n",
    "* Cash/Total Assets\n",
    "* Quick Assets/Current Liability\n",
    "* Cash/Current Liability\n",
    "* Current Liability to Assets\n",
    "* Operating Funds to Liability\n",
    "* Inventory/Working Capital\n",
    "* Inventory/Current Liability\n",
    "* Current Liabilities/Liability\n",
    "* Working Capital/Equity\n",
    "* Current Liabilities/Equity\n",
    "* Long-term Liability to Current Assets\n",
    "* Retained Earnings to Total Assets\n",
    "* Total income/Total expense\n",
    "* Total expense/Assets\n",
    "* Current Asset Turnover Rate: Current Assets to Sales\n",
    "* Quick Asset Turnover Rate: Quick Assets to Sales\n",
    "* Working capitcal Turnover Rate: Working Capital to Sales\n",
    "* Cash Turnover Rate: Cash to Sales\n",
    "* Cash Flow to Sales\n",
    "* Fixed Assets to Assets\n",
    "* Current Liability to Liability\n",
    "* Current Liability to Equity\n",
    "* Equity to Long-term Liability\n",
    "* Cash Flow to Total Assets\n",
    "* Cash Flow to Liability\n",
    "* CFO to Assets\n",
    "* Cash Flow to Equity\n",
    "* Current Liability to Current Assets\n",
    "* Liability-Assets Flag: 1 if Total Liability exceeds Total Assets, 0 otherwise\n",
    "* Net Income to Total Assets\n",
    "* Total assets to GNP price\n",
    "* No-credit Interval\n",
    "* Gross Profit to Sales\n",
    "* Net Income to Stockholder's Equity\n",
    "* Liability to Equity\n",
    "* Degree of Financial Leverage (DFL)\n",
    "* Interest Coverage Ratio (Interest expense to EBIT)\n",
    "* Net Income Flag: 1 if Net Income is Negative for the last two years, 0 otherwise\n",
    "* Equity to Liability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b651d67",
   "metadata": {},
   "source": [
    "---\n",
    "# Dataset Exploration \n",
    "\n",
    "1. Load in each dataset, then report on how many rows and columns each dataset has AND the label distibution (i.e how many data items are in each label -- for example, the iris dataset has 50 flowers across each of the 3 flower species labels)\n",
    "\n",
    "\n",
    "2. Based on this dataset size information and the given dataset decriptions alone, which of the supervised learning models (Logistic Regression, K-NN, Naive Bayes, SVMs, decision trees, random forests, or Neural Networks) do you think will peform best on each dataset? Which do you think will perform worst? Explain your reasoning for each choice. \n",
    "    NOTE: DO NOT RUN ANY EXPERIMENTS BEFOREHAND! You should use your intuition and class discussions for this! \n",
    "    \n",
    "\n",
    "3. Get a baseline accuracy using the naive model (i.e. a model where you assign the same label to all your testing data and that label is the one that appeared the most in your training data) for each of the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fbb8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d859e76",
   "metadata": {},
   "source": [
    "# Model Comparisons and Analysis\n",
    "\n",
    "4.Compare the average testing accuracy as well as runtime across each of the 4 datasets for each of the following experiment set-ups: \n",
    "\n",
    "    1. Logistic Regression \n",
    "\n",
    "    2. K-Nearest Neighbors (K-NN) for euclidean and manhattan distance and for k values = {5, 10, 15, 20, 25, 30, 35, 40, 45, 50}\n",
    "\n",
    "    3. Naive Bayes \n",
    "\n",
    "    4. Decision Trees using citerion = \"entropy\" across various values for max_depth  \n",
    "    \n",
    "    5. Random Forests\n",
    "    \n",
    "    6. Neural Networks\n",
    "\n",
    "Note: you may use k-fold cross validation for these experiments\n",
    "\n",
    "\n",
    "5. Were your predicitons from step 2 correct? Why or why not? \n",
    "\n",
    "\n",
    "6. Which model would you chose for each dataset? Explain your reasoning and use the results of your experiments and any domain knowledge you have to support your argument. \n",
    "\n",
    "\n",
    "7. Why do you think certain models performed better on some of your datasets versus others? Are there certain attributes/aspects of each dataset that some machine learning models prefer? \n",
    "\n",
    "\n",
    "8. Now repeat these experiments from question 4, but this time run PCA to reduce the dimensions of your feature set beforehand. Try experimenting with different values for the number of dimensions returned by PCA (you will likely need different values for each dataset since they are all different sizes). What happens to the performance as you reduce the dimesions? Do some models do better/worse? Does it depend on the dataset? Why is this happening? Explain your reasoning. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9388ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
