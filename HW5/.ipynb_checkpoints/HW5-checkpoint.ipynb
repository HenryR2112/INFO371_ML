{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a520e8eb",
   "metadata": {},
   "source": [
    "# INFO371 Problem Set: Classification and k-Nearest Neighbors\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Please write clearly! Answer each question in a way that if the code chunks are removed from your document, the result are still readable!\n",
    "* Discussing the solutions and getting help is all right, but you have to solve the problem your own. Do not copy-paste from others!\n",
    "* Make sure you show your work!\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "In this assignment, we are going to be looking at the Wisconsin Breast Cancer Dataset (WBCD).\n",
    "The dataset orginates from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) and it contains\n",
    "569 cases from November 1995.  \n",
    "\n",
    "The data includes tumor diagnosis, with \"M\" meaning cancer (malignant) and \"B\" meaning no cancer (benign), and 10 features describing the physical properties of the cell nuclei from biopsy samples.  Each\n",
    "feature is represented three times, once for mean, once for standard deviation, and once for the worst values.  More specifically, the variables are: \n",
    "\n",
    "* id -> case id\n",
    "* Diagnosis -> (M = malignant, B = benign).  These are the labels or the part you normally predict . \n",
    "* ten real-valued features computed for each cell nucleus. For each feature the mean, standard error, and ''worst'' or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features.  For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius. \n",
    "   \n",
    "It contains the following features:\n",
    "   * radius -> mean of distances from center to points on the\n",
    "     perimeter\n",
    "   * texture -> standard deviation of gray-scale values\n",
    "   * perimeter\n",
    "   * area\n",
    "   * smoothness -> local variation in radius lengths\n",
    "   * compactness -> $ perimeter^2 / area - 1.0$\n",
    "   * concavity -> severity of concave portions of the contour\n",
    "   * concpoints -> number of concave portions of the contour\n",
    "   * symmetry\n",
    "   * fracdim -> fractal dimension, $coastline\\ approximation - 1$\n",
    "\n",
    "\n",
    "Your task is to predict diagnosis (cancer or not cancer) based on this data, and our focus is to use $k$-NN and different metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94fc582",
   "metadata": {},
   "source": [
    "## Explore the data  and  Experimental Setup (13pt)\n",
    "\n",
    "As the first step, explore the data and establish a baseline!\n",
    "\n",
    "1. Load the data, Ignore id.\n",
    "\n",
    "\n",
    "2. Create a table where you show ranges (min and max) for each variable.  You may include more statistics you consider useful. \n",
    "\n",
    "\n",
    "\n",
    "3. Randomly select 80% of the data and put this in a training dataset df, and place the remaining 20% in a testing dataset df. \n",
    "\n",
    "\n",
    "\n",
    "4. Using this test/train spilt, create a naive model -- i.e. a model that predicts every case to the majority category/label. What is the training vs testing accuracy of this model? Is this what you expected, and why?\n",
    "\n",
    "\n",
    "\n",
    "5. Add code to measure the running time of your algorithm. How long does it take to predict labels for the test data? \n",
    "\n",
    "    Note: you can use python's time library to meaure runtime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0526de",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13579\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#code goes here\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   5252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5262\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5263\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5397\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5405\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5406\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"wdbc.csv.bz2\")\n",
    "\n",
    "# leave the following line untouched, it will help ensure that your \"random\" split is the same \"random\" split used by the rest of the class\n",
    "np.random.seed(seed=13579)\n",
    "\n",
    "#code goes here\n",
    "df = df.drop('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5e098",
   "metadata": {},
   "source": [
    "## Compare Performance to k-NN (32pts)\n",
    "\n",
    "Now that you have a baseline performance, your next task is to compare the performace using a k-NN model and the Mahalanobis distance function. For these experiments, make sure you use the same test/train split as you did for your baseline.    \n",
    "\n",
    "6. Using the same test/train split as the naive model, create a 1-NN model with Mahalanobis distance metric the then report what is the training vs testing accuracy of this model. How much better did 1-NN do compared to the naive baseline? \n",
    "\n",
    "\n",
    "7. Add code to measure the running time of your algorithm. How long does it take to predict labels for the test data? \n",
    "\n",
    "\n",
    "8. Now repeat steps 6-7 (i.e. get training and testing accuracy of the model and the runtime) for k values from 2 to 15. \n",
    "\n",
    "\n",
    "9. Using those resilts, create two line charts: 1) comparing performance and 2) comparing runtime as you vary k. Your k values should be on the x axis, and your y axis should be accuracy or run time in seconds. \n",
    "\n",
    "\n",
    "10. Describe your observations from these experiments. For example, this about whether there are any trade-offs with chosing certain k values. Is there anything about the data/experiment/model that impacts performance in a good and bad way? How well did the k-nn model do compared to the naive baseline? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b4a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a5fab",
   "metadata": {},
   "source": [
    "## Feature Transformation (30pts)\n",
    "\n",
    "As we talked about in class, normalizing your features can have a huge impact on k-nn model performance. When we ran the experiments above, we did not normalize our features! let's now examine how this might impact the model. \n",
    "\n",
    "11. Your first step is to write your own normalization function for this dataset and apply it to your training and testing data. Remeber that normalization typically takes in an array of values for a given feature, and returns the normalized array (subtract the mean and divide by the standard deviation). Note that you might already have these numbers in the dataset itself! \n",
    "\n",
    "\n",
    "\n",
    "12. With your features normalized, repeat the experiments you did earlier by doing the following: \n",
    "        a. Create a k-nn model with Mahalanobis distance metric\n",
    "        b. run the model for all k-values between 1-15\n",
    "        c. report the training and testing accuracy and the runtime \n",
    "\n",
    "\n",
    "\n",
    "13. Using those resilts, create two line charts: 1) comparing performance and 2) comparing runtime as you vary k. Your k values should be on the x axis, and your y axis should be accuracy or run time in seconds.\n",
    "\n",
    "\n",
    "\n",
    "14. Now compare your performance between the normalized and non-normalized datasets. How much did normalization impact performance?  It might help to show both performances on the same line chart to really compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code goes here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c42da",
   "metadata": {},
   "source": [
    "## Cross-Validation (25pts)\n",
    "\n",
    "Up until this point, all of our experiments have used the same test/train spilt. But that might not reflect average peformance. We could have, for example, gotten lucky and randomly chosen a test/train split that happened to improve performance. Instead, we want to get average performance over a number of data splits to get a better idea of how our model is working. \n",
    "\n",
    "To do this, we need to use cross-validation to get average performance. For our experiments, use 10-fold cross-validation sames as you did in lab. \n",
    "\n",
    "15. Repeat the experiments you did earlier on the normalized dataset by doing the following: \n",
    "        a. Create a k-nn model with Mahalanobis distance metric\n",
    "        b. run the model with 10-fold cross validation for all k-values between 1-15\n",
    "        c. report the average training and average testing accuracy and the average runtime for all k values \n",
    "      \n",
    "      \n",
    "16. Using those resilts, create two line charts: 1) comparing average performance and 2) comparing average runtime as you vary k. Your k values should be on the x axis, and your y axis should be accuracy or run time in seconds.\n",
    "\n",
    "\n",
    "\n",
    "17. Describe your observations from these experiments. Did anything change when you did cross-validation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a48761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62fe82b",
   "metadata": {},
   "source": [
    "## Extra Credit (+10 pts)\n",
    "\n",
    "For extra credit, repeat the cross-validation experiments (i.e. varying the k-values) on the normalized dataset BUT this time compare performance and runtime between all 4 distance metrics you used in lab. Then analyze your results and discuss the benefits/trade-offs for each of the metrics for this dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
