{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36333990",
   "metadata": {},
   "source": [
    "# INFO 3071 Lab - Artificial Neural Networks\n",
    "\n",
    "This lab asks you to play with using Multi-Layer Perceptron models (aka: neural networks) and examining how your architecture choices affect your accuracy. Like with the trees lab, we will use the Wisconsin\n",
    "Diagnostic Breast Cancer (WDBC) data for categorization. \n",
    "\n",
    "The aim of this lab is to give you some experience with neural networks.  Try to get as good accuracy as possible (while also minimizing overfitting)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7865efc5",
   "metadata": {},
   "source": [
    "## Classification \n",
    "In this task you work with WDBC data.  As a reminder, your task is to\n",
    "predict __diagnosis__ (''M'' = cancer, ''B'' = no cancer).  \n",
    "\n",
    "\n",
    "1. Load wdbc data and ensure it looks good.\n",
    "\n",
    "\n",
    "2. Create your feature matrix $X$ and label vector $y$.  The former should contain all 30 features,  everything, except __diagnosis__ and __id__.  The latter should be __diagnosis__, converted to either logical or numeric variable (otherwise sklearn will fail).\n",
    "\n",
    "\n",
    "3.  Split your data into training and validation chunks (or do cross validation below, but that is slower).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabd5d07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T01:43:30.030709Z",
     "start_time": "2024-05-24T01:43:29.132799Z"
    }
   },
   "outputs": [],
   "source": [
    "#code goes here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"wdbc.csv.bz2\")\n",
    "\n",
    "y = df.diagnosis\n",
    "y = (y == 'M').astype(int)\n",
    "df = df.drop(columns=['id', 'diagnosis'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, y, test_size=0.20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a686ef",
   "metadata": {},
   "source": [
    "Now everything should be ready for us to train some Neural Networks.  Your\n",
    "task is to analyze the effect of changing the __hidden_layer_sizes__ hyperparameter of [MLPClassifier](https://scikit-learn.org/stable/modules/neural_networks_supervised.html). \n",
    "\n",
    "\n",
    "4. Get a baseline testing and training accuracy for your model using the default paramters.\n",
    "\n",
    "\n",
    "5. Experiment with different numers of layers (and number of nodes at each layer) to try to get the best possible accuracy. The __hidden_layer_sizes__ parameter accepts a set where the length is the number of hidden layers and each element is the number of nodes in each layer. For example if I set as hidden_layer_sizes=(5, 2, 3) then my neural network will have 3 hidden layers where the first layer has 5 nodes, the second 2 nodes, and the third has 3 nodes. \n",
    "\n",
    "\n",
    "6. Report on what the best \"architecture\" you got. Tell us how manuy layers you used and the total number of nodes you used to get your best accuracy. \n",
    "\n",
    "\n",
    "7. Does your model overfit? Back up your claim with evidence. \n",
    "        Hint: you need to examine test/train accuracy as you vary the complexity of the model.\n",
    "\n",
    "\n",
    "8. Finally, compare the best accuracy you achieved using neural networks with a similar accuracy using a default Random Forest model. Which model gives you better accuracy? Which model is more prone to overfitting with this dataset? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20bb1048af8a3da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T02:01:31.150311Z",
     "start_time": "2024-05-24T02:01:30.934858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default testing accuracy: 0.9473684210526315\n",
      "default training accuracy: 0.9406593406593406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "print(\"default testing accuracy:\", model.score(x_test, y_test))\n",
    "print(\"default training accuracy:\", model.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c076b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code goes here\n",
    "test_accuracy = []\n",
    "train_accuracy = []\n",
    "for i in range(2,7):\n",
    "    for j in range(2,7):\n",
    "        for k in range(2,7):\n",
    "            model = MLPClassifier(hidden_layer_sizes=(i,j,k))\n",
    "            model.fit(x_train, y_train)\n",
    "            test = ((model.score(x_test, y_test)), (i,j,k))\n",
    "            train = ((model.score(x_train, y_train)), (i,j,k))\n",
    "            test_accuracy.append(test)\n",
    "            train_accuracy.append(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32a8a0831137199b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T02:01:08.033717Z",
     "start_time": "2024-05-24T02:01:08.022687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing architecture:  (0.956140350877193, (5, 3, 5))\n",
      "training architecture:  (0.9428571428571428, (5, 3, 4))\n"
     ]
    }
   ],
   "source": [
    "print(\"testing architecture: \", max(test_accuracy))\n",
    "print(\"training architecture: \",max(train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c89b0bbf84c815",
   "metadata": {},
   "source": [
    "The results above indicate that the best model found in a simple 3 layer structure uses a 5,3,4. The loop above only restricts to three layers for complexity purposes and only perceptron layers up 6, but the above architecture came out on top in test and training. Based on the testing the model does not seem to overfit particularly aggressively given the training and testing accuracy are so similar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41979ab65ed3cfbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T01:55:42.249850Z",
     "start_time": "2024-05-24T01:55:42.064864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.ensemble as e\n",
    "\n",
    "\n",
    "forest = e.RandomForestClassifier(criterion = 'entropy')\n",
    "m = forest.fit(x_train, y_train)\n",
    "print(m.score(x_train, y_train))\n",
    "m.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30cc7283abde95b",
   "metadata": {},
   "source": [
    "Based on the results above it seems clear that the random forest and the NN are comparable in terms of testing accuracy but that the random forest may be more prone to overfitting. This can be seen as it exhibited perfect training accuracy. Looking in literature though it seems clear that my findings are against the norms which consider random forests more robust than NN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
