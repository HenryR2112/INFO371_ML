{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d16b00",
   "metadata": {},
   "source": [
    "# INFO371 Homework: Neural Networks and Support Vector Machines\n",
    "\n",
    "Your task for this assignment is to explore a dataset using both neural networks and SVMs in order to give you some experience with hyperparameter tuning and visualizing decision boundaries. You'll want to make sure you are familiar with the documentation for both methods before starting the assignment. \n",
    "\n",
    "## Data\n",
    "In this assignment, you will work with a dataset to try to predicit whether someone is at high or low risk of having a heart attack given some general health information about each person. The dataset has the following features: \n",
    "\n",
    "* Age : Age of the patient\n",
    "* Sex : Sex of the patient (0 = Male, 1 = Female)\n",
    "* exang: exercise induced angina (1 = yes; 0 = no)\n",
    "* caa: number of major vessels (0-3)\n",
    "* cp : Chest Pain type\n",
    "     * Value 0: typical angina\n",
    "     * Value 1: atypical angina\n",
    "     * Value 2: non-anginal pain\n",
    "     * Value 3: asymptomatic\n",
    "* trtbps : resting blood pressure (in mm Hg)\n",
    "* chol : cholestoral in mg/dl fetched via BMI sensor\n",
    "* fbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "* rest_ecg : resting electrocardiographic results\n",
    "    * Value 0: normal\n",
    "    * Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "    * Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "* thalach : maximum heart rate achieved\n",
    "* old peak: ST depression induced by exercise relative to rest\n",
    "* slp: the slope of the peak exercise ST segment\n",
    "    * 0 = unsloping\n",
    "    * 1 = flat\n",
    "    * 2 = downsloping\n",
    "* thall : thalassemia\n",
    "    * 0 = null\n",
    "    * 1 = fixed defect\n",
    "    * 2 = normal\n",
    "    * 3 = reversable defect\n",
    "* output : 0= less chance of heart attack 1= more chance of heart attack\n",
    "\n",
    "Note that the column \"output\" is your label (i.e. the thing you are trying to predict). \n",
    "\n",
    "---\n",
    "For some more information on some of the health definitions: \n",
    "* [Angina](https://www.nhs.uk/conditions/angina/#:~:text=Angina%20is%20chest%20pain%20caused,of%20these%20more%20serious%20problems): chest pain due to reduced blood flow to the heart muscles. There're 3 types of angina: stable angina, unstable angina, and variant angina.\n",
    "\n",
    "* ECG: short for electrocardiogram, it's a routine test usually done to check the heart's electrical activity.\n",
    "\n",
    "* [ST depression](https://litfl.com/st-segment-ecg-library/): a type of ST-segment abnormality. the ST segment is the flat, isoelectric part of the ECG and it represents the interval between ventricular depolarization and repolarization.\n",
    "\n",
    "* Thalassemia: is a genetic blood disorder that is characterized by a lower rate of hemoglobin than normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab5dafe",
   "metadata": {},
   "source": [
    "## Dataset Exploration and Experiment Set-Up\n",
    "\n",
    "1. load the dataset and ensure it looks good \n",
    "\n",
    "\n",
    "2. Plot your data using PCA to reduce the dimensions to a 2D space. Make sure to color each point in the dataset occording to each label/output.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602e2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6735bee5",
   "metadata": {},
   "source": [
    "## Running Neural Networks\n",
    "\n",
    "3. Using the default parameters, train a Neural Networl model and examine the examine average performance across different random splits. Run the model at least 10 times on different random splits of your data and report the average testing and training accuracy as well as the standard deviation. For an idea on how to do this, take a look at some of the lecture code we’ve done in class. Please don't use the cross-validation function here -- we want you to write this part yourself. \n",
    "\n",
    "    Hint – its probably a good idea to write a function to do this since you will be using this code to tune the various parameters. \n",
    "    \n",
    "    Hint - you are welcome to use any code from previous homework assignments. \n",
    "\n",
    "\n",
    "7. Now lets examine what happens as you increase the complexity of the model. Tune the model by examining various numers of layers (and number of nodes at each layer) to try to get the best possible accuracy. The hidden_layer_sizes parameter accepts a set where the length is the number of hidden layers and each element is the number of nodes in each layer. For example if I set as hidden_layer_sizes=(5, 2, 3) then my neural network will have 3 hidden layers where the first layer has 5 nodes, the second 2 nodes, and the third has 3 nodes. max-tree-depth. \n",
    "\n",
    "8. Plot the __average__ training and testing accuracy as you increase the number of total nodes in your model. (NOTE - this means you'll have to run your model multiple times to get average accuracy. Use your function from step 3 to get this score). Accuracy should be on the y-axis and number of nodes should be on the x-axis. \n",
    "\n",
    "\n",
    "\n",
    "8. Now plot the __average__ training and testing accuracy as you increase the number of layers in your model. (NOTE - this means you'll have to run your model multiple times to get average accuracy. Use your function from step 3 to get this score). Accuracy should be on the y-axis and number of layers should be on the x-axis. \n",
    "\n",
    "\n",
    "\n",
    "9. Using these figures, explain when your model is overfitting and underfitting. \n",
    "\n",
    "\n",
    "10. EXTRA CREDIT (5pts) -- Experiment with regularization (through different alpha terms) to combat overfitting. Use average test/train accuracy scores to find the best alpha values. Be sure to compare overall performance (both with repect to over/underfitting and the impact on model accuracy) with your non-regularized model from above.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe363ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a37cd",
   "metadata": {},
   "source": [
    "## Running SVMs\n",
    "\n",
    "Now lets experiment with SVMs.  \n",
    "\n",
    "12. __BEFORE RUNNING ANY CODE__, predict which kernel function (linear, rbf, sigmoid, or polynomial) you think will perform the best. Use your figure from step 2 to help you decide. \n",
    "\n",
    "\n",
    "13. For each kernel method, train an SVM model and report the average training and test accuracy. Was your prediction correct? Which method peformed the best? \n",
    "\n",
    "\n",
    "14. Now plot the decision boundaries for each kernel method and identify the support vectors on your plot. You should have four plots in total for this question. [This tutorial](https://towardsdatascience.com/visualizing-support-vector-machine-decision-boundary-69e7591dacea) has code that will help you do this. What do these figures tell you about the different kernel methods? Which do you think fit the data the best? Does this match your answer in question 13? \n",
    "\n",
    "\n",
    "15. Compare your SVM performance with your Neural Netowrk performance. Which perfomed better? Which was more prone to overfitting? What does this tell you about when to use each model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c5d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code goes here "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
